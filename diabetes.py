# -*- coding: utf-8 -*-
"""diabetes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g2G4D3goFzXU6xyCnOOTWAzA84scohTn

Load CSV File
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import joblib
df = pd.read_csv("diabetes_binary_health_indicators_BRFSS2015.csv")
df.head()

"""Data Cleansing & Feature Selection"""

df = df.dropna()
df.drop_duplicates(inplace=True)

# df.drop(df[df['PhysHlth'] > 30].index, inplace = True)
# df.drop(df[df['MentHlth'] > 30].index, inplace = True)
# df.drop(df[((df['CholCheck'] == 0) & (df['HighChol'] == 1))].index, inplace = True)

# df.drop(columns=['Education', 'Income', 'AnyHealthcare', 'NoDocbcCost'], inplace=True)

df.head()

from sklearn.feature_selection import mutual_info_classif
x = df.iloc[:, 1:]
y = df.iloc[:, 0]

importance = mutual_info_classif(x,y)

feat_importance = pd.Series(importance, df.columns[1: len(df.columns)])
feat_importance.plot(kind='barh', color='teal')

df.drop(columns=['Stroke', 'HvyAlcoholConsump', 'MentHlth', 'NoDocbcCost'], inplace=True)
# multiply by 5 so when we predict w enter the actual age
df.loc[:, 'Age'] *= 5

df.drop_duplicates(inplace=True)
len(df.index)

"""Correlation Visualaization"""

plt.figure(figsize = (15,10))
cormat = df.corr()
round(cormat,2)

sns.heatmap(cormat, cmap="BuGn", annot=True)

"""Normalization:"""

def min_max_scaling(series):
    return (series - series.min()) / (series.max() - series.min())

for col in df.columns:
    df[col] = min_max_scaling(df[col])

df.head()

"""Model Training"""

from sklearn.model_selection import train_test_split

x = df.iloc[:, 1:]
y = df.iloc[:, 0]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True, random_state=42)

"""Dataset Balancing by oversampling"""

from imblearn.over_sampling import SMOTE


sm = SMOTE(sampling_strategy='auto', random_state=7)
x_train, y_train = sm.fit_sample(x_train, y_train)


oversampled_train = pd.concat([pd.DataFrame(y_train), pd.DataFrame(x_train)], axis=1)
oversampled_train.columns = df.columns
plt.figure(figsize=(8, 8))
sns.countplot('Diabetes_binary', data=oversampled_train)
plt.title('Balanced Diabetes Binary')
plt.show()

"""HeatMap after dataset balance"""

plt.figure(figsize = (15,10))
cormat = oversampled_train.corr()
round(cormat,2)

sns.heatmap(cormat, cmap="BuGn", annot=True)

# Model Evaluation
def model_evaluation(y_pred, test_y):
  print("Accuracy:", metrics.accuracy_score(test_y, y_pred))
  print("Precision:", metrics.precision_score(test_y, y_pred))
  print("F1 Score:", metrics.f1_score(test_y, y_pred))
  print("Confusion Matrix:", metrics.confusion_matrix(test_y, y_pred))

"""Logistic Regression"""

from sklearn.linear_model import LogisticRegression
import sklearn.metrics as metrics
from matplotlib import pyplot

logModel = LogisticRegression(max_iter=10000)
logModel.fit(x_train, y_train)

joblib.dump(logModel, "logistic_regreession.pkl")

logModelLoaded = joblib.load("logistic_regreession.pkl")

logy_pred = logModelLoaded.predict(x_test)
model_evaluation(logy_pred, y_test)

"""Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier

rfc = RandomForestClassifier(n_estimators=200)
rfc.fit(x_train, y_train)
joblib.dump(rfc, "random_forest_classifier.pkl")

rfcModelLoaded = joblib.load("random_forest_classifier.pkl")

rfcy_pred = rfcModelLoaded.predict(x_test)
model_evaluation(rfcy_pred, y_test)

"""SVM"""

from sklearn import svm
# oversampling
from imblearn.over_sampling import SMOTE

# kernel='rbf', gamma=0.001, C=10
# svmx_train, svmx_test, svmy_train, svmy_test = train_test_split(x, y, test_size=0.5)
# svmModel = svm.SVC(kernel='linear', verbose=True)
# svmModel.fit(svmx_train, svmy_train)

svmx_train, svmx_test, svmy_train, svmy_test = train_test_split(x, y, test_size=0.3, shuffle=True, random_state=44)

# Resample the minority class. You can change the strategy to 'auto' if you are not sure.
sm = SMOTE(sampling_strategy='auto', random_state=7)
svmx_train, svmy_train = sm.fit_sample(svmx_train, svmy_train)

svmModel = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo', verbose=True)
svmModel.fit(svmx_train, svmy_train)
joblib.dump(svmModel, "svm_model.pkl")

import joblib

svmx_train, svmx_test, svmy_train, svmy_test = train_test_split(x, y, test_size=0.3, shuffle=True, random_state=44)
svmModelLoaded = joblib.load("svm_model.pkl")

svm_pred = svmModelLoaded.predict(svmx_test)
model_evaluation(svm_pred, svmy_test)

"""Decision Tree"""

from sklearn import tree

treeModel = tree.DecisionTreeClassifier()
treeModel = treeModel.fit(x_train, y_train)

joblib.dump(treeModel, "decision_tree_model.pkl")

import joblib

treeModelLoaded = joblib.load("decision_tree_model.pkl")


tree_pred = treeModelLoaded.predict(x_test)
model_evaluation(tree_pred, y_test)

"""Test The Model"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import joblib

# pd.DataFrame([{'HighBP': 1.0, 'HighChol': 1.0, 'CholCheck': 1.0, 'BMI': 40.0, 'Smoker': 1.0, 'Stroke': 0.0, 'HeartDiseaseorAttack': 0.0, 'PhysActivity': 0.0, 'Fruits': 0.0, 'Veggies': 1.0, 'HvyAlcoholConsump': 0.0, 'GenHlth': 5.0, 'MentHlth': 18.0, 'PhysHlth': 15.0, 'DiffWalk': 1.0, 'Sex': 0.0, 'Age': 45.0}])
# Calculate min max scale for normalization of new data
df2 = pd.read_csv("diabetes_binary_health_indicators_BRFSS2015.csv")
df2 = df2.dropna()
df2.drop_duplicates(inplace=True)

# df2.drop(columns=['Education', 'Income', 'AnyHealthcare', 'NoDocbcCost'], inplace=True)
df2.drop(columns=['Stroke', 'HvyAlcoholConsump', 'MentHlth', 'NoDocbcCost'], inplace=True)
df2.loc[:, 'Age'] *= 5

df2.drop_duplicates(inplace=True)
# Diabetes_binary          0.0
# HighBP                   1.0
# HighChol                 1.0
# CholCheck                1.0
# BMI                     40.0
# Smoker                   1.0
# HeartDiseaseorAttack     0.0
# PhysActivity             0.0
# Fruits                   0.0
# Veggies                  1.0
# AnyHealthcare            1.0
# GenHlth                  5.0
# PhysHlth                15.0
# DiffWalk                 1.0
# Sex                      0.0
# Age                     45.0
# Education                4.0
# Income                   3.0

def min_max_scaling_nd(series, newVal):
    return (newVal - series.min()) / (series.max() - series.min())

print("Diabetes Predection Test:\nEnter 1 for yes and 0 for no \n\n")

print("Do you have high blood pressure?")
HighBP = int(input())
print("Do you have High cholesterol?")
HighChol = int(input())
print("Did you check your Cholestrol Level")
CholCheck = int(input())
print("What is your BMI")
BMI = float(input())
print("Are you a smoker")
Smoker = int(input())
print("Do you have a heart disease or did you have a heart attack?")
HeartDiseaseorAttack = int(input())
print("Do you do any physical activity?")
PhysActivity = int(input())
print("Do you eat fruits?")
Fruits = int(input())
print("Do you eat vegetables?")
Veggies = int(input())
print("Do you have any kind of health care coverage, including health insurance, prepaid plans such as HMOs, or government plans such as Medicare, or Indian Health Service?")
AnyHealthcare = int(input())
print("Would you say that in general your health is (scale 1-5) (1 = excellent, 2 = very good, 3 = good, 4 = fair, 5 = poor): ")
GenHlth = int(input())
print("how many days during the past 30 days was your mental health not good?")
PhysHlth = int(input())
print("Do you have serious difficulty walking or climbing stairs?")
DiffWalk = int(input())
print("What is your Sex (0 for female and 1 for male)?")
Sex = int(input())
print("What is your Age?")
Age = int(input())
print("What is the highest grade or year of school you completed?")
Education = int(input())
print("Is your annual household income from all sources?")
Income = int(input())

# {'HighBP': 1.0, 'HighChol': 1.0, 'CholCheck': 1.0, 'BMI': 40.0, 'Smoker': 1.0, 'Stroke': 0.0, 
# 'HeartDiseaseorAttack': 0.0, 'PhysActivity': 0.0, 'Fruits': 0.0, 'Veggies': 1.0, 'HvyAlcoholConsump': 0.0, 
# 'GenHlth': 5.0, 'MentHlth': 18.0, 'PhysHlth': 15.0, 'DiffWalk': 1.0, 'Sex': 0.0, 'Age': 45.0}
new_inp = {
    "HighBP": float(HighBP),
    "HighChol": float(HighChol),
    "BMI": float(BMI),
    "CholCheck": float(CholCheck),
    "Smoker": float(Smoker),
    "HeartDiseaseorAttack": float(HeartDiseaseorAttack),
    "PhysActivity": float(PhysActivity),
    "Fruits": float(Fruits),
    "Veggies": float(Veggies),
    "AnyHealthcare": float(AnyHealthcare),
    "GenHlth": float(GenHlth),
    "PhysHlth": float(PhysHlth),
    "DiffWalk": float(DiffWalk),
    "Sex": float(Sex),
    "Age": float(Age),
    "Education": float(Education),
    "Income": float(Income)
}

for col in new_inp:
    new_inp[col] = min_max_scaling_nd(df2[col], new_inp[col])

# print(new_inp)
ldtf = []
for col in df2.columns[1:]:
    ldtf.append(new_inp[col])

new_inp = pd.DataFrame([ldtf], columns=df2.columns[1:])

# new_x_pred = np.array(new_inp.values())
# new_x_pred = new_x_pred.reshape(-1,1)
# new_x_pred = [new_x_pred]

print("Predicted values from different models:")
# Logistic regression
logModelLoaded = joblib.load("logistic_regreession.pkl")
logy_pred = logModelLoaded.predict(new_inp)
print("Logistic Regression: ", logy_pred[0])

# svm
# svmModelLoaded = joblib.load("svm_model.pkl")
# svm_pred = svmModelLoaded.predict(new_inp)
# print("SVM: ", svm_pred[0])

# tree model
treeModelLoaded = joblib.load("decision_tree_model.pkl")
tree_pred = treeModelLoaded.predict(new_inp)
print("Decision Tree: ", tree_pred[0])

# random forest classifier
rfcModelLoaded = joblib.load("random_forest_classifier.pkl")
rfcModelLoaded = treeModelLoaded.predict(new_inp)
print("Random Forest Classifier: ", rfcModelLoaded[0])